{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 金融异常检测任务"
   ],
   "id": "c4b039a9cbcd3a3"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 实验介绍\n",
    "\n",
    "反欺诈是金融行业永恒的主题，在互联网金融信贷业务中，数字金融反欺诈技术已经得到广泛应用并取得良好效果，这其中包括了近几年迅速发展并在各个领域\n",
    "得到越来越广泛应用的神经网络。本项目以互联网智能风控为背景，从用户相互关联和影响的视角，探索满足风控反欺诈领域需求的，可拓展、高效的神经\n",
    "网络应用方案，从而帮助更好地识别欺诈用户。\n",
    "\n",
    "本项目主要关于实现预测模型(**项目用图神经网络举例，具体实现可以使用其他模型**)，进行节点异常检测任务，并验证模型精度。而本项目基于的数据集[DGraph](https://dgraph.xinye.com/introduction)，[DGraph](https://dgraph.xinye.com/introduction)\n",
    "是大规模动态图数据集的集合，由真实金融场景中随着时间演变事件和标签构成。\n",
    "\n",
    "### 1.1 实验目的\n",
    "\n",
    "- 了解如何使用Pytorch进行神经网络训练\n",
    "- 了解如何使用Pytorch-geometric等图网络深度学习库进行简单图神经网络设计(推荐使用GAT, GraphSAGE模型)。\n",
    "- 了解如何利用MO平台进行模型性能评估。\n",
    "\n",
    "### 1.2 预备知识\n",
    "- 具备一定的深度学习理论知识，如卷积神经网络、损失函数、优化器，训练策略等。\n",
    "- 了解并熟悉Pytorch计算框架。\n",
    "- 学习Pytorch-geometric，请前往：https://pytorch-geometric.readthedocs.io/en/latest/\n",
    "    \n",
    "### 1.3实验环境\n",
    "- numpy = 1.26.4  \n",
    "- pytorch = 2.3.1  \n",
    "- torch_geometric = 2.5.3  \n",
    "- torch_scatter = 2.1.2  \n",
    "- torch_sparse = 0.6.18  "
   ],
   "id": "68deacf2d11484fc"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 实验内容"
   ],
   "id": "a0b4d792b1a994aa"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 数据集信息\n",
    "DGraph-Fin 是一个由数百万个节点和边组成的有向无边权的动态图。它代表了Finvolution Group用户之间的社交网络，其中一个节点对应一个Finvolution 用户，从一个用户到另一个用户的边表示**该用户将另一个用户视为紧急联系人**。\n",
    "下面是`位于dataset/DGraphFin目录`的DGraphFin数据集的描述:\n",
    "```\n",
    "x:  20维节点特征向量\n",
    "y:  节点对应标签，一共包含四类。其中类1代表欺诈用户而类0代表正常用户(实验中需要进行预测的两类标签)，类2和类3则是背景用户，即无需预测其标签。\n",
    "edge_index:  图数据边集,每条边的形式(id_a,id_b)，其中ids是x中的索引\n",
    "edge_type: 共11种类型的边\n",
    "edge_timestamp: 脱敏后的时间戳\n",
    "train_mask, valid_mask, test_mask: 训练集，验证集和测试集掩码\n",
    "```\n",
    "本预测任务为识别欺诈用户的节点预测任务,只需要将欺诈用户（Class 1）从正常用户（Class 0）中区分出来。需要注意的是，其中测试集中样本对应的label**均被标记为-100**。"
   ],
   "id": "830f13f9fe7d3017"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "### 2.2 导入相关包\n",
    "\n",
    "导入相应模块，设置数据集路径、设备等。"
   ],
   "id": "54e58c46c55422f8"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-02T15:14:02.079883Z",
     "start_time": "2024-10-02T15:13:52.995567Z"
    }
   },
   "source": [
    "from utils import DGraphFin\n",
    "from utils.utils import prepare_folder\n",
    "from utils.evaluator import Evaluator\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "\n",
    "import torch_geometric.transforms as T\n",
    "\n",
    "import numpy as np\n",
    "from torch_geometric.data import Data\n",
    "import os\n",
    "\n",
    "#设置gpu设备\n",
    "device = 0\n",
    "device = f'cuda:{device}' if torch.cuda.is_available() else 'cpu'\n",
    "device = torch.device(device)\n",
    "print(f'Using {device}')"
   ],
   "id": "23d24cb261e82511",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda:0\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 数据处理\n",
    "\n",
    "在使用数据集训练网络前，首先需要对数据进行归一化等预处理，如下："
   ],
   "id": "b948e390ff4ec8de"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-02T12:51:17.003273Z",
     "start_time": "2024-10-02T12:51:15.531445Z"
    }
   },
   "source": [
    "path='./datasets/632d74d4e2843a53167ee9a1-momodel/' #数据保存路径\n",
    "save_dir='./results/' #模型保存路径\n",
    "dataset_name='DGraph'\n",
    "# dataset = DGraphFin(root=path, name=dataset_name, transform=T.Compose([T.ToUndirected(),T.ToSparseTensor()]))\n",
    "# dataset = DGraphFin(root=path, name=dataset_name, transform= T.Compose([T.ToUndirected(),T.ToSparseTensor()]))\n",
    "dataset = DGraphFin(root=path, name=dataset_name, transform=T.ToSparseTensor())\n",
    "nlabels = dataset.num_classes\n",
    "if dataset_name in ['DGraph']:\n",
    "    nlabels = 2    #本实验中仅需预测类0和类1\n",
    "\n",
    "data = dataset[0]\n",
    "data.adj_t = data.adj_t.to_symmetric() #将有向图转化为无向图\n",
    "\n",
    "\n",
    "if dataset_name in ['DGraph']:\n",
    "    x = data.x\n",
    "    x = (x - x.mean(0)) / x.std(0)\n",
    "    data.x = x\n",
    "if data.y.dim() == 2:\n",
    "    data.y = data.y.squeeze(1)\n",
    "\n",
    "split_idx = {'train': data.train_mask, 'valid': data.valid_mask, 'test': data.test_mask}  #划分训练集，验证集\n",
    "\n",
    "train_idx = split_idx['train']\n",
    "result_dir = prepare_folder(dataset_name,'mlp')\n"
   ],
   "id": "5aed28dc5535ebde",
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这里我们可以查看数据各部分维度"
   ],
   "id": "e28a71f3b6e5bc9b"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-02T12:51:23.281478Z",
     "start_time": "2024-10-02T12:51:23.267949Z"
    }
   },
   "source": [
    "print(data)\n",
    "print(data.x.shape)  #feature\n",
    "print(data.y.shape)  #label"
   ],
   "id": "47b856cc19475404",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(x=[3700550, 20], edge_attr=[4300999], y=[3700550], train_mask=[857899], valid_mask=[183862], test_mask=[183840], adj_t=[3700550, 3700550, nnz=7994520])\n",
      "torch.Size([3700550, 20])\n",
      "torch.Size([3700550])\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 定义模型\n",
    "这里我们使用简单的多层感知机作为例子："
   ],
   "id": "4a467bd11d7b06b3"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-02T12:51:24.171109Z",
     "start_time": "2024-10-02T12:51:24.147899Z"
    }
   },
   "source": [
    "class MLP(torch.nn.Module):\n",
    "    def __init__(self\n",
    "                 , in_channels\n",
    "                 , hidden_channels\n",
    "                 , out_channels\n",
    "                 , num_layers\n",
    "                 , dropout\n",
    "                 , batchnorm=True):\n",
    "        super(MLP, self).__init__()\n",
    "        self.lins = torch.nn.ModuleList()\n",
    "        self.lins.append(torch.nn.Linear(in_channels, hidden_channels))\n",
    "        self.batchnorm = batchnorm\n",
    "        if self.batchnorm:\n",
    "            self.bns = torch.nn.ModuleList()\n",
    "            self.bns.append(torch.nn.BatchNorm1d(hidden_channels))\n",
    "        for _ in range(num_layers - 2):\n",
    "            self.lins.append(torch.nn.Linear(hidden_channels, hidden_channels))\n",
    "            if self.batchnorm:\n",
    "                self.bns.append(torch.nn.BatchNorm1d(hidden_channels))\n",
    "        self.lins.append(torch.nn.Linear(hidden_channels, out_channels))\n",
    "\n",
    "        self.dropout = dropout\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        for lin in self.lins:\n",
    "            lin.reset_parameters()\n",
    "        if self.batchnorm:\n",
    "            for bn in self.bns:\n",
    "                bn.reset_parameters()\n",
    "\n",
    "    def forward(self, x):\n",
    "        for i, lin in enumerate(self.lins[:-1]):\n",
    "            x = lin(x)\n",
    "            if self.batchnorm:\n",
    "                x = self.bns[i](x)\n",
    "            x = F.relu(x)\n",
    "            x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        x = self.lins[-1](x)\n",
    "        return F.log_softmax(x, dim=-1)\n"
   ],
   "id": "ea781c9b62eeeb87",
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "配置后续训练、验证、推理用到的参数。可以调整以下超参以提高模型训练后的验证精度：\n",
    "\n",
    "- `epochs`：在训练集上训练的代数；\n",
    "- `lr`：学习率；\n",
    "- `num_layers`：网络的层数；\n",
    "- `hidden_channels`：隐藏层维数；\n",
    "- `dropout`：dropout比例；\n",
    "- `weight_decay`：正则化项的系数。"
   ],
   "id": "92838a3aabcb63fd"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-02T12:51:25.651498Z",
     "start_time": "2024-10-02T12:51:25.631418Z"
    }
   },
   "source": [
    "mlp_parameters = {\n",
    "    'lr': 0.01\n",
    "    , 'num_layers': 2\n",
    "    , 'hidden_channels': 128\n",
    "    , 'dropout': 0.0\n",
    "    , 'batchnorm': False\n",
    "    , 'weight_decay': 5e-7\n",
    "                  }\n",
    "epochs = 200\n",
    "log_steps =10 # log记录周期\n"
   ],
   "id": "337e1ea9a170197",
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "初始化模型，并使用**Area Under the Curve (AUC)** 作为模型评价指标来衡量模型的表现。AUC通过对ROC曲线下各部分的面积求和而得。\n",
    "\n",
    "具体计算过程参见 https://github.com/scikit-learn/scikit-learn/blob/baf828ca1/sklearn/metrics/_ranking.py#L363"
   ],
   "id": "222f86148653b991"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-02T12:51:28.438528Z",
     "start_time": "2024-10-02T12:51:26.178431Z"
    }
   },
   "source": [
    "para_dict = mlp_parameters\n",
    "model_para = mlp_parameters.copy()\n",
    "model_para.pop('lr')\n",
    "model_para.pop('weight_decay')\n",
    "model = MLP(in_channels=data.x.size(-1), out_channels=nlabels, **model_para).to(device)\n",
    "print(f'Model MLP initialized')\n",
    "\n",
    "\n",
    "eval_metric = 'auc'  #使用AUC衡量指标\n",
    "evaluator = Evaluator(eval_metric)\n"
   ],
   "id": "5065e205cf765521",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model MLP initialized\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 训练\n",
    "\n",
    "使用训练集中的节点用于训练模型，并使用验证集进行挑选模型。"
   ],
   "id": "887dcd3aefc497b8"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-02T12:51:28.581084Z",
     "start_time": "2024-10-02T12:51:28.565403Z"
    }
   },
   "source": [
    "def train(model, data, train_idx, optimizer):\n",
    "    # data.y is labels of shape (N, )\n",
    "    model.train()\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    train_x = data.x[train_idx]\n",
    "    train_y = data.y[train_idx]\n",
    "    out = model(train_x)\n",
    "\n",
    "    loss = F.nll_loss(out, train_y)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    return loss.item()\n"
   ],
   "id": "adc5fa07d7d5880f",
   "outputs": [],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-02T12:51:29.379635Z",
     "start_time": "2024-10-02T12:51:29.370120Z"
    }
   },
   "source": [
    "def test(model, data, split_idx, evaluator):\n",
    "    # data.y is labels of shape (N, )\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "\n",
    "        losses, eval_results = dict(), dict()\n",
    "        for key in ['train', 'valid']:\n",
    "            node_id = split_idx[key]\n",
    "            out = model(data.x[node_id])\n",
    "            y_pred = out.exp()  # (N,num_classes)\n",
    "\n",
    "            losses[key] = F.nll_loss(out, data.y[node_id]).item()\n",
    "            eval_results[key] = evaluator.eval(data.y[node_id], y_pred)[eval_metric]\n",
    "\n",
    "    return eval_results, losses, y_pred\n"
   ],
   "id": "af3bd6bba7a662eb",
   "outputs": [],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-02T12:26:19.963029Z",
     "start_time": "2024-10-02T12:25:16.137861Z"
    }
   },
   "source": [
    "print(sum(p.numel() for p in model.parameters()))  #模型总参数量\n",
    "\n",
    "model.reset_parameters()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=para_dict['lr'], weight_decay=para_dict['weight_decay'])\n",
    "best_valid = 0\n",
    "min_valid_loss = 1e8\n",
    "\n",
    "data = data.to(device)\n",
    "\n",
    "for epoch in range(1,epochs + 1):\n",
    "    loss = train(model, data, train_idx, optimizer)\n",
    "    eval_results, losses, out = test(model, data, split_idx, evaluator)\n",
    "    train_eval, valid_eval = eval_results['train'], eval_results['valid']\n",
    "    train_loss, valid_loss = losses['train'], losses['valid']\n",
    "\n",
    "    if valid_loss < min_valid_loss:\n",
    "        min_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), save_dir+'/model.pt') #将表现最好的模型保存\n",
    "\n",
    "    if epoch % log_steps == 0:\n",
    "        print(f'Epoch: {epoch:02d}, '\n",
    "              f'Loss: {loss:.4f}, '\n",
    "              f'Train: {100 * train_eval:.3f}, ' # 我们将AUC值乘上100，使其在0-100的区间内\n",
    "              f'Valid: {100 * valid_eval:.3f} ')\n"
   ],
   "id": "9eb3bbdb0b9a957c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2946\n",
      "Epoch: 10, Loss: 0.0822, Train: 64.918, Valid: 65.146 \n",
      "Epoch: 20, Loss: 0.1017, Train: 67.229, Valid: 67.114 \n",
      "Epoch: 30, Loss: 0.0814, Train: 69.276, Valid: 68.666 \n",
      "Epoch: 40, Loss: 0.0690, Train: 70.172, Valid: 69.451 \n",
      "Epoch: 50, Loss: 0.0651, Train: 69.100, Valid: 68.533 \n",
      "Epoch: 60, Loss: 0.0654, Train: 69.802, Valid: 69.153 \n",
      "Epoch: 70, Loss: 0.0646, Train: 70.624, Valid: 69.992 \n",
      "Epoch: 80, Loss: 0.0645, Train: 70.971, Valid: 70.236 \n",
      "Epoch: 90, Loss: 0.0643, Train: 70.984, Valid: 70.246 \n",
      "Epoch: 100, Loss: 0.0642, Train: 71.157, Valid: 70.385 \n",
      "Epoch: 110, Loss: 0.0641, Train: 71.318, Valid: 70.531 \n",
      "Epoch: 120, Loss: 0.0641, Train: 71.440, Valid: 70.629 \n",
      "Epoch: 130, Loss: 0.0640, Train: 71.536, Valid: 70.701 \n",
      "Epoch: 140, Loss: 0.0640, Train: 71.627, Valid: 70.776 \n",
      "Epoch: 150, Loss: 0.0639, Train: 71.711, Valid: 70.839 \n",
      "Epoch: 160, Loss: 0.0639, Train: 71.784, Valid: 70.894 \n",
      "Epoch: 170, Loss: 0.0639, Train: 71.847, Valid: 70.944 \n",
      "Epoch: 180, Loss: 0.0639, Train: 71.900, Valid: 70.988 \n",
      "Epoch: 190, Loss: 0.0638, Train: 71.947, Valid: 71.024 \n",
      "Epoch: 200, Loss: 0.0638, Train: 71.989, Valid: 71.053 \n"
     ]
    }
   ],
   "execution_count": 34
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "inputHidden": false
   },
   "source": [
    "### 2.6 模型预测"
   ],
   "id": "26832f504e8db39f"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-02T12:26:42.097122Z",
     "start_time": "2024-10-02T12:26:42.060064Z"
    }
   },
   "source": [
    "model.load_state_dict(torch.load(save_dir+'/model.pt')) #载入验证集上表现最好的模型\n",
    "def predict(data,node_id):\n",
    "    \"\"\"\n",
    "    加载模型和模型预测\n",
    "    :param node_id: int, 需要进行预测节点的下标\n",
    "    :return: tensor, 类0以及类1的概率, torch.size[1,2]\n",
    "    \"\"\"\n",
    "    # -------------------------- 实现模型预测部分的代码 ---------------------------\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        out = model(data.x[node_id])\n",
    "        y_pred = out.exp()  # (N,num_classes)\n",
    "\n",
    "    return y_pred\n"
   ],
   "id": "e305d2e40b2cb2ef",
   "outputs": [],
   "execution_count": 35
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-02T12:26:43.691095Z",
     "start_time": "2024-10-02T12:26:43.654930Z"
    }
   },
   "source": [
    "dic={0:\"正常用户\",1:\"欺诈用户\"}\n",
    "node_idx = 0\n",
    "y_pred = predict(data, node_idx)\n",
    "print(y_pred)\n",
    "print(f'节点 {node_idx} 预测对应的标签为:{torch.argmax(y_pred)}, 为{dic[torch.argmax(y_pred).item()]}。')\n",
    "\n",
    "node_idx = 1\n",
    "y_pred = predict(data, node_idx)\n",
    "print(y_pred)\n",
    "print(f'节点 {node_idx} 预测对应的标签为:{torch.argmax(y_pred)}, 为{dic[torch.argmax(y_pred).item()]}。')\n"
   ],
   "id": "2be22422faf86d10",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.9957, 0.0043], device='cuda:0')\n",
      "节点 0 预测对应的标签为:0, 为正常用户。\n",
      "tensor([0.9743, 0.0257], device='cuda:0')\n",
      "节点 1 预测对应的标签为:0, 为正常用户。\n"
     ]
    }
   ],
   "execution_count": 36
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 作业评分\n",
    "\n",
    "**作业要求**：    \n",
    "                         \n",
    "1. 请加载你认为训练最佳的模型（不限于图神经网络)\n",
    "2. 提交的作业包括【程序报告.pdf】和代码文件。\n",
    "\n",
    "**注意：**\n",
    "          \n",
    "1. 在训练模型等过程中如果需要**保存数据、模型**等请写到 **results** 文件夹，如果采用 [离线任务](https://momodel.cn/docs/#/zh-cn/%E5%9C%A8GPU%E6%88%96CPU%E8%B5%84%E6%BA%90%E4%B8%8A%E8%AE%AD%E7%BB%83%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%A8%A1%E5%9E%8B) 请务必将模型保存在 **results** 文件夹下。\n",
    "2. 训练出自己最好的模型后，先按照下列 cell 操作方式实现 NoteBook 加载模型测试；请测试通过在进行【系统测试】。\n",
    "3. 点击左侧栏`提交作业`后点击`生成文件`则只需勾选 `predict()` 函数的cell，即【**模型预测代码答题区域**】的 cell。\n",
    "4. 请导入必要的包和第三方库 (包括此文件中曾经导入过的)。\n",
    "5. 请加载你认为训练最佳的模型，即请按要求填写**模型路径**。\n",
    "6. `predict()`函数的输入和输出请不要改动。"
   ],
   "id": "58e3ac7092ec1c1b"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "===========================================  **模型预测代码答题区域**  =========================================== \n",
    "\n",
    "在下方的代码块中编写 **模型预测** 部分的代码，请勿在别的位置作答"
   ],
   "id": "43699e0287a76e34"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "select": true
   },
   "outputs": [],
   "source": [
    "## 生成 main.py 时请勾选此 cell\n",
    "from utils import DGraphFin\n",
    "from utils.evaluator import Evaluator\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.data import Data\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# 这里可以加载你的模型\n",
    "model = model.load_state_dict(torch.load('./results/model.pt'))\n",
    "\n",
    "def predict(data,node_id):\n",
    "    \"\"\"\n",
    "    加载模型和模型预测\n",
    "    :param node_id: int, 需要进行预测节点的下标\n",
    "    :return: tensor, 类0以及类1的概率, torch.size[1,2]\n",
    "    \"\"\"\n",
    "\n",
    "    # 模型预测时，测试数据已经进行了归一化处理\n",
    "    # -------------------------- 实现模型预测部分的代码 ---------------------------\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        out = model(data.x[node_id])\n",
    "        y_pred = out.exp()  # (N,num_classes)\n",
    "\n",
    "    return y_pred\n"
   ],
   "id": "95846699255ace6e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "b23c308a162c5946"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 4. 其它模型",
   "id": "db44c1ee7ef057a2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-02T15:14:21.633115Z",
     "start_time": "2024-10-02T15:14:21.624592Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def load_data(folder, dataset_name, force_to_symmetric: bool = False):\n",
    "    dataset = DGraphFin(root=folder, name=dataset_name, transform=T.ToSparseTensor())\n",
    "    # dataset = DGraphFin(root=path, name=dataset_name, transform= T.Compose([T.ToUndirected(),T.ToSparseTensor()]))\n",
    "\n",
    "    nlabels = dataset.num_classes\n",
    "    if dataset_name in ['DGraph']:\n",
    "        nlabels = 2  # 本实验中仅需预测类0和类1\n",
    "\n",
    "    data = dataset[0]\n",
    "    if force_to_symmetric:\n",
    "        data.adj_t = data.adj_t.to_symmetric()  # 将有向图转化为无向图\n",
    "\n",
    "    if data.edge_index is None:\n",
    "        row, col, _ = data.adj_t.t().coo()\n",
    "        data.edge_index = torch.stack([row, col], dim=0)\n",
    "\n",
    "    if dataset_name in ['DGraph']:\n",
    "        x = data.x\n",
    "        x = (x - x.mean(0)) / x.std(0)\n",
    "        data.x = x\n",
    "    if data.y.dim() == 2:\n",
    "        data.y = data.y.squeeze(1)\n",
    "\n",
    "    split_idx = {'train': data.train_mask, 'valid': data.valid_mask, 'test': data.test_mask}  # 划分训练集，验证集\n",
    "\n",
    "    train_idx = split_idx['train']\n",
    "    return data"
   ],
   "id": "f4457aed2bc6d88c",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-02T15:23:20.058871Z",
     "start_time": "2024-10-02T15:15:39.871649Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from tqdm import tqdm\n",
    "import os\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from models.GraphSAGE import GraphSAGE as Model\n",
    "# from utils.dgraphfin import load_data\n",
    "from utils.evaluator import Evaluator\n",
    "\n",
    "\n",
    "def train(model, data, train_idx, optimizer, cache_path):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    out = model(data.x, data.adj_t)\n",
    "\n",
    "    Path(cache_path).parent.mkdir(parents=True, exist_ok=True)\n",
    "    torch.save(out, cache_path)\n",
    "\n",
    "    out = out[train_idx]\n",
    "\n",
    "    loss = F.nll_loss(out, data.y[train_idx])\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    return loss.item()\n",
    "\n",
    "\n",
    "def valid(model, data, split_idx, evaluator, cache_path):\n",
    "    if os.path.exists(cache_path):\n",
    "        out = torch.load(cache_path)\n",
    "    else:\n",
    "        with torch.no_grad():\n",
    "            model.eval()\n",
    "            out = model(data.x, data.adj_t)\n",
    "    y_pred = out.exp()\n",
    "    losses, eval_results = dict(), dict()\n",
    "    for key in ['train', 'valid']:\n",
    "        node_id = split_idx[key]\n",
    "        losses[key] = F.nll_loss(out[node_id], data.y[node_id]).item()\n",
    "        eval_results[key] = evaluator.eval(data.y[node_id], y_pred[node_id])['auc']\n",
    "    return eval_results, losses\n",
    "\n",
    "\n",
    "def train_epoch(\n",
    "    model, data, optimizer, evaluator, lr, min_valid_loss, epoch, model_desc, stop_count,\n",
    "    use_early_stop=False,\n",
    "    use_lr_scheduler=False\n",
    "):\n",
    "    split_idx = {'train': data.train_mask, 'valid': data.valid_mask, 'test': data.test_mask}  # 划分训练集，验证集\n",
    "    cache_path = Path(f'./results/out-{model_desc}.pt')\n",
    "    cache_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    loss = train(model, data, data.train_mask, optimizer, cache_path)\n",
    "    eval_results, losses = valid(model, data, split_idx, evaluator, cache_path)\n",
    "    valid_loss = losses['valid']\n",
    "    early_stop = False\n",
    "    # 保存最好的模型\n",
    "    if valid_loss < min_valid_loss:\n",
    "        stop_count = 0\n",
    "        model_save_path = Path(f'results/model-{model_desc}.pt')\n",
    "        model_save_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "        torch.save(model.state_dict(), model_save_path)\n",
    "        min_valid_loss = valid_loss\n",
    "        if cache_path.exists():\n",
    "            out = torch.load(cache_path)\n",
    "            torch.save(out, cache_path.with_name(f'out-best-{model_desc}.pt'))\n",
    "    else:\n",
    "        stop_count += 1\n",
    "        if stop_count == 5 and use_lr_scheduler:\n",
    "            for param_group in optimizer.param_groups:\n",
    "                lr *= 0.5\n",
    "                param_group['lr'] = 0.5\n",
    "        if stop_count == 10 and use_early_stop:\n",
    "            early_stop = True\n",
    "\n",
    "    train_log = {\n",
    "        'epoch': epoch,\n",
    "        't.loss': losses['train'],\n",
    "        't.auc': eval_results['train'],\n",
    "        'v.loss': losses['valid'],\n",
    "        'v.auc': eval_results['valid'],\n",
    "        'lr': lr,\n",
    "        's.cnt': stop_count,\n",
    "        'min.v.loss': min_valid_loss,\n",
    "    }\n",
    "    with open(f'results/train_log-{model_desc}.csv', 'a' if epoch > 0 else 'w', newline='') as f:\n",
    "        pd.DataFrame({k: [v] for k, v in train_log.items()}).to_csv(f, header=f.tell() == 0, index=False)\n",
    "    return min_valid_loss, lr, stop_count, early_stop, train_log\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # 设置gpu设备\n",
    "    device = 0\n",
    "    device = f'cuda:{device}' if torch.cuda.is_available() else 'cpu'\n",
    "    device = torch.device(device)\n",
    "    print(f'Using device: {device}')\n",
    "\n",
    "    # 加载数据\n",
    "    data = load_data('./datasets/632d74d4e2843a53167ee9a1-momodel/', 'DGraph', force_to_symmetric=False)\n",
    "    data = data.to(device)\n",
    "\n",
    "    lr = 0.005\n",
    "    print(f'batch_size: all data, lr: {lr}')\n",
    "\n",
    "    model_params = {\n",
    "        \"h_c\": 32,\n",
    "        \"dropout\": 0.0,\n",
    "        \"lr\": lr,\n",
    "        \"epochs\": 800,\n",
    "        \"layer\": 3,\n",
    "    }\n",
    "\n",
    "    model = Model(\n",
    "        in_c=20,\n",
    "        out_c=2,\n",
    "        h_c= 32,\n",
    "        dropout= 0.0,\n",
    "    )\n",
    "    model_desc = f'GraphSAGE-{\"-\".join([f\"{k}_{v}\" for k, v in model_params.items() ])}'\n",
    "\n",
    "    model = model.to(device)\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=lr)\n",
    "    evaluator = Evaluator('auc')\n",
    "\n",
    "    min_valid_loss = 1e10\n",
    "    stop_count = 0\n",
    "\n",
    "    epoch_iter = tqdm(range(0, 800))\n",
    "    for epoch in epoch_iter:\n",
    "        min_valid_loss, lr, stop_count, early_stop, train_log = train_epoch(\n",
    "            model, data, optimizer, evaluator, lr, min_valid_loss, epoch, model_desc, stop_count\n",
    "        )\n",
    "        epoch_iter.set_postfix(**train_log)\n",
    "    print(f'Training finished with {epoch} epochs')"
   ],
   "id": "dc532612977611cb",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda:0\n",
      "batch_size: all data, lr: 0.005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 800/800 [07:38<00:00,  1.75it/s, epoch=799, lr=0.005, min.v.loss=0.0629, s.cnt=0, t.auc=0.762, t.loss=0.062, v.auc=0.745, v.loss=0.0629] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training finished with 799 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-02T15:54:25.688688Z",
     "start_time": "2024-10-02T15:54:23.378413Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from tqdm import tqdm\n",
    "import os\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import Tensor\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from models.GraphSAGE import GraphSAGE as Model\n",
    "from utils.evaluator import Evaluator\n",
    "\n",
    "# 设置gpu设备\n",
    "device = 0\n",
    "device = f'cuda:{device}' if torch.cuda.is_available() else 'cpu'\n",
    "device = torch.device(device)\n",
    "\n",
    "data = load_data('./datasets/632d74d4e2843a53167ee9a1-momodel/', 'DGraph', force_to_symmetric=True)\n",
    "data = data.to(device)\n",
    "lr = 0.005\n",
    "model_params = {\n",
    "    \"h_c\": 32,\n",
    "    \"dropout\": 0.0,\n",
    "    \"lr\": lr,\n",
    "    \"epochs\": 800,\n",
    "    \"layer\": 3,\n",
    "}\n",
    "\n",
    "\n",
    "model = Model(\n",
    "    in_c=20,\n",
    "    out_c=2,\n",
    "    h_c= 32,\n",
    "    dropout= 0.0,\n",
    ")\n",
    "model_desc = f'GraphSAGE-{\"-\".join([f\"{k}_{v}\" for k, v in model_params.items() ])}'\n",
    "model_save_path = f'results/model-{model_desc}.pt'\n",
    "model.load_state_dict(torch.load(model_save_path, map_location=device))\n",
    "\n",
    "cache_path = f'./results/out-best-{model_desc}.pt'\n",
    "\n",
    "\n",
    "def predict(data, node_id):\n",
    "    if os.path.exists(cache_path):\n",
    "        out = torch.load(cache_path, map_location=device)\n",
    "    else:\n",
    "        with torch.no_grad():\n",
    "            model.eval()\n",
    "            out = model(data.x, data.adj_t)\n",
    "\n",
    "    pred = out[node_id].exp()\n",
    "    return pred.squeeze(0)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    dic = {0: \"正常用户\", 1: \"欺诈用户\"}\n",
    "    node_idx = 0\n",
    "    y_pred = predict(data, node_idx)\n",
    "    print(y_pred)\n",
    "    print(f'节点 {node_idx} 预测对应的标签为:{torch.argmax(y_pred)}, 为{dic[torch.argmax(y_pred).item()]}。')\n",
    "\n",
    "    node_idx = 1\n",
    "    y_pred = predict(data, node_idx)\n",
    "    print(y_pred)\n",
    "    print(f'节点 {node_idx} 预测对应的标签为:{torch.argmax(y_pred)}, 为{dic[torch.argmax(y_pred).item()]}。')"
   ],
   "id": "b79e9cade0de993d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.9856, 0.0144], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "节点 0 预测对应的标签为:0, 为正常用户。\n",
      "tensor([0.9767, 0.0233], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "节点 1 预测对应的标签为:0, 为正常用户。\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "198f5ca3f1d45ed9"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agent",
   "language": "python",
   "name": "agent"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
